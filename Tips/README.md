# Best Tips for Acing CKA, CKAD, and CKS Exams

## **1. Master Basic `vim` for File Editing**

The exam environment uses `vim` as the default editor. While you don't need to be an expert, these essential commands will help you work efficiently.

---

### Key Commands

#### Basic Operations
- **Open a File**: `vim file.yaml`
- **Enter Insert Mode**: Press `i`
- **Exit Insert Mode**: Press `Esc`
- **Undo Changes**: Press `u`
- **Save and Exit**: 
  - `:wq` (write and quit)
  - `:x` (save and exit - only writes if changes were made)


> ðŸ’¡ **Tip**: `:x` is slightly more efficient than `:wq` because it only writes to the file if you've made changes. This can be faster when you're just viewing files.

#### Quick Edit-Test Workflow with Ctrl+Z
The most efficient way to edit and validate YAML files is by using vim's suspend feature:

1. **Edit in vim**:
   ```bash
   vim deployment.yaml
   ```

2. **Suspend vim**:
   - First press `ESC` to enter Normal mode (this is crucial!)
   - Then press `Ctrl+Z`
   - This suspends vim and returns you to the shell
   - Your vim session and all changes are preserved
   
   > âš ï¸ **Important**: Always ensure you're in Normal mode by pressing `ESC` before using `Ctrl+Z`. If you try to use `Ctrl+Z` while in Insert mode, it won't work as expected.

3. **Run kubectl commands**:
   ```bash
   kubectl apply -f deployment.yaml --dry-run=client
   ```

4. **Resume vim**:
   ```bash
   fg
   ```
   - This brings back your vim session exactly where you left off

ðŸ’¡ **Pro Tips**:
- Use `:w` to save before suspending if you want to validate changes
- Keep track of error line numbers from kubectl to jump directly to them in vim
- Use `!!` to repeat your last kubectl command after returning from vim

#### Navigation
- **Search for Text**: Type `/string` and press Enter
  - Use `n` for next match
  - Use `N` for previous match
- **Jump to Line**: 
  - Inside file: `:41` (jumps to line 41)
  - Opening file: `vim +41 deployment.yaml`

#### YAML Formatting
- **Indent**: Highlight lines (`Shift + V`) â†’ Press `>`
- **Unindent**: Highlight lines (`Shift + V`) â†’ Press `<`
- Press `.` to continue in that direction.

---

### Example: Debugging a Kubernetes Deployment with an Error

Suppose you are working on a deployment YAML file and encounter an error when applying it:

#### Deployment YAML (`deployment.yaml`)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app-container
        image: nginx:1.21.1
        ports:
        - containerPort: 80
      - name: another-container
        image: busybox:latest
         ports:            # Intentional Error: Indentation mismatch
        - containerPort: 8080

## How to Debug Using `vim`

### Step 1: Apply the YAML File
Run the following command to apply the deployment YAML file:
```bash
kubectl apply -f deployment.yaml
```

### Error Message Example
If there's an error in the file, you might see a message like this:
```plaintext
error: error validating "deployment.yaml": error converting YAML to JSON: yaml: line 20: did not find expected key
```

### Step 2: Open the File in `vim` and Jump to Line 20

1. Open the file in `vim`:
   ```bash
   vim deployment.yaml
   ```

Once the file is open, jump directly to line 20 by typing:
```plaintext
:20
```

Fix your error(s) and save file with:
```plaintext
:x
```

### Recommended `.vimrc` Configuration
```vim
set expandtab
set shiftwidth=2
set softtabstop=2
```

`### Handling Immutable Resources When `vim` Creates a Temporary File

When editing an immutable resource (e.g., PersistentVolumeClaim), Kubernetes might reject the changes, and `kubectl` saves the changes to a temporary file instead. You can use the temporary file to forcefully replace the resource.

#### Example: Editing a PersistentVolumeClaim (PVC)

1. Attempt to edit the PVC:
   ```bash
   kubectl edit pvc alpha-pvc -n alpha
   ```

1.  If the PVC is immutable, you might see an error like this:
   
    ```bash
    error: persistentvolumeclaims "alpha-pvc" is invalid
    spec: Forbidden: spec is immutable after creation except resources.requests and volumeAttributes for bound claims
    A copy of your changes has been stored to "/tmp/kubectl-edit-3898228328.yaml"
    error: Edit cancelled, no valid changes were saved.
    ```

3.  Locate the temporary file thatÂ `kubectl`Â created:
    ```bash
    /tmp/kubectl-edit-3898228328.yaml
    ```

4.  Forcefully replace the PVC using the temporary file:
    ```bash
    kubectl replace -f /tmp/kubectl-edit-3898228328.yaml --force --grace-period=0
    ```

* * * * *

#### Explanation

-   Immutable Resources:Â Certain Kubernetes resources, like PersistentVolumeClaims (PVCs), have immutable fields that cannot be updated directly.
-   Temporary File:Â When you useÂ `kubectl edit`Â on an immutable resource,Â `kubectl`Â saves the changes to a temporary file and aborts the edit.
-   `kubectl replace`: Replaces the resource with the updated manifest.
-   `--force`: Deletes the existing resource and recreates it.
-   `--grace-period=0`: Ensures the resource is terminated immediately without waiting for the default grace period.

* * * * *

#### Best Practice

If replacing a resource, ensure you understand the implications, as it will delete and recreate the resource. For PVCs, this might temporarily disconnect Pods relying on the PVC.


### Recommended `.vimrc` Configuration
```vim
set expandtab
set shiftwidth=2
set softtabstop=2
```


## 2. Kubernetes DNS Patterns and Service Discovery

Understanding DNS patterns is crucial for service and pod communication across your cluster. Kubernetes DNS follows specific hierarchical patterns and includes special handling for pod IPs.

### Service DNS Patterns

1. Same Namespace: 
```bash
service-name
# Example: mysql
```

2. Cross Namespace: 
```bash
service-name.namespace
# Example: mysql.databases
```

3. Fully Qualified Domain Name (FQDN): 
```bash
service-name.namespace.svc.cluster.local
# Example: mysql.databases.svc.cluster.local
```

### Pod DNS Resolution

Pods use a different DNS pattern than services. To resolve a pod by DNS:

1. Get the pod's IP:
```bash
# Method 1: Using kubectl
$ kubectl get pod nginx-pod -o jsonpath='{.status.podIP}'
10.244.2.45

# Method 2: Using custom columns
$ kubectl get pod nginx-pod -o custom-columns=IP:.status.podIP
IP
10.244.2.45
```

2. Convert IP to DNS format:
- Replace dots with dashes in the IP
- Append the namespace and cluster domain
```bash
# Format: pod-ip-with-dashes.namespace.pod.cluster.local
10-244-2-45.default.pod.cluster.local
```

### DNS Lookup Examples

1. Looking up a service:
```bash
$ kubectl run tmp-shell --rm -it --image nicolaka/netshoot -- bash
$ nslookup mysql.databases
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      mysql.databases
Address 1: 10.96.45.10 mysql.databases.svc.cluster.local
```

2. Looking up a pod:
```bash
$ kubectl run tmp-shell --rm -it --image nicolaka/netshoot -- bash
$ nslookup 10-244-2-45.default.pod.cluster.local
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      10-244-2-45.default.pod.cluster.local
Address 1: 10.244.2.45
```

### Practical Examples

1. Get pod IP and convert to DNS name:
```bash
# One-liner to get pod DNS name
$ POD_IP=$(kubectl get pod nginx-pod -o jsonpath='{.status.podIP}') && echo ${POD_IP//./-}.default.pod.cluster.local
10-244-2-45.default.pod.cluster.local
```

2. Create an alias for quick pod DNS lookup:
```bash
# Add to ~/.bashrc or ~/.zshrc
alias k8s-pod-dns='POD_IP=$(kubectl get pod $1 -o jsonpath="{.status.podIP}") && echo ${POD_IP//./-}.$2.pod.cluster.local'

# Usage: k8s-pod-dns <pod-name> <namespace>
$ k8s-pod-dns nginx-pod default
10-244-2-45.default.pod.cluster.local
```

### DNS Resolution Hierarchy

1. Services:
```
service-name â†’ service-name.namespace â†’ service-name.namespace.svc â†’ service-name.namespace.svc.cluster.local
```

2. Pods:
```
pod-ip-with-dashes â†’ pod-ip-with-dashes.namespace.pod â†’ pod-ip-with-dashes.namespace.pod.cluster.local
```

### Troubleshooting DNS

1. Verify DNS resolution from within a pod:
```bash
$ kubectl run dns-test --rm -it --image nicolaka/netshoot -- bash
$ dig mysql.databases.svc.cluster.local
```

2. Check DNS service status:
```bash
$ kubectl get pods -n kube-system -l k8s-app=kube-dns
$ kubectl logs -n kube-system -l k8s-app=kube-dns
```

ðŸ’¡ **Pro Tips**:
- Always start with the simplest DNS pattern and expand as needed
- Use temp debug pods with networking tools (like nicolaka/netshoot) for DNS troubleshooting
- Remember that pod DNS names are based on their IPs, not their kubernetes pod names
- Service DNS names are more stable than pod DNS names since pod IPs change on restart

Understanding DNS patterns is crucial for service communication across your cluster.

### DNS Hierarchy
1. Same Namespace: `service-name`
2. Cross Namespace: `service-name.namespace`
3. FQDN: `service-name.namespace.svc.cluster.local`

> ðŸ’¡ **Pro Tip**: Start with the simplest pattern and expand as needed.

## 3. Master Pod and Service Communication

Understanding how Pods communicate with each other and with external clients is crucial in Kubernetes. Services provide the abstraction needed to route traffic to the appropriate Pods seamlessly.

### Service Types

- **ClusterIP** (Default):
  - **Purpose:** Internal cluster communication.
  - **Access Pattern:** `service-name:port`.
  - **Use Case:** Facilitates communication between microservices within the cluster.
  - **Example:** A frontend service accessing a backend service via its `ClusterIP`.

- **NodePort**:
  - **Purpose:** Expose a service on the node's IP at a static port.
  - **Port Range:** 30000-32767.
  - **Access Pattern:** `node-ip:node-port`.
  - **Use Case:** Useful for simple external access to applications during development or testing.

- **LoadBalancer**:
  - **Purpose:** Provides an external IP via a cloud provider's load balancer.
  - **Access Pattern:** `external-ip:port`.
  - **Use Case:** Best for production deployments needing external traffic routing to the cluster.

- **ExternalName**:
  - **Purpose:** Maps a service to an external DNS record (e.g., external databases or APIs).
  - **Access Pattern:** Uses a CNAME record to redirect traffic.
  - **Example:** `db.example.com` as the external database endpoint.

---

### Common Service Patterns

#### ClusterIP Example
```yaml
apiVersion: v1
kind: Service
metadata:
  name: app-service
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
    - name: http         # Optional name for the port
      port: 80           # Service port (used for communication)
      targetPort: 8080   # Internal Pod container port
### Key Details
- **name**: A unique identifier for the port (useful when multiple ports are defined in a service).
- **port**: The port the service exposes to other services or Pods in the cluster.
- **targetPort**: The internal container port where the application listens. If omitted, it defaults to the value of `port`.

---

### NodePort Example
```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  type: NodePort
  selector:
    app: web
  ports:
    - name: http
      port: 80           # Service port
      targetPort: 8080   # Internal Pod container port
      nodePort: 30080    # Fixed external port on the node

### Key Details
- **nodePort**: Maps the service to a specific port on each node, making it accessible externally using the node's IP.
- Naming the port with `name` is useful for distinguishing between multiple ports (e.g., `http` vs. `https`).

---

### Quick Service Creation

You can easily create services for existing workloads using the `kubectl expose` command.

```bash
# Expose a Deployment with a ClusterIP service
kubectl expose deployment nginx --name=nginx-svc --port=80 --target-port=8080 

# Expose a Pod with a NodePort service
kubectl expose pod mypod --name=mypod-svc --port=80 --type=NodePort

### Key Notes
- If `type` is not specified, `ClusterIP` is used by default.
- The `targetPort` represents the internal port the container is listening on. If omitted, it defaults to the value of `port`.
- Use the `--port` flag to define the service's exposed port.

---

### Naming Ports in Services

Kubernetes allows naming ports with the `name` field.

#### Benefits of Naming Ports
- Useful when multiple ports are defined in the service.
- Helps identify ports easily in configuration files.
- Required when using protocols like HTTP/2 or gRPC, as some controllers (e.g., Ingress) rely on port names to route traffic.

#### Example with Named Ports
```yaml
apiVersion: v1
kind: Service
metadata:
  name: multi-port-service
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
    - name: http
      port: 80
      targetPort: 8080
    - name: https
      port: 443
      targetPort: 8443
```


## 4. Master `jsonpath` for Kubernetes Queries

# Practical Guide to Kubernetes JSONPath Queries

This guide shows how to extract and format information from Kubernetes objects using JSONPath and custom columns, with real-world examples and their outputs.

### 1. Understanding jq paths - The JSONPath Cheat Code

One of the most challenging aspects of using JSONPath with Kubernetes is knowing the correct path to the data you want. While you could read the API documentation or inspect raw JSON output, there's a better way: `jq -c paths`.

The `jq -c paths` command is like having a map of every possible path in your JSON data. Here's why it's so powerful:

#### Basic Usage
```bash
# Get ALL possible paths in a pod's JSON
$ kubectl get pod nginx-pod -o json | jq -c paths
["apiVersion"]
["kind"]
["metadata","annotations"]
["metadata","creationTimestamp"]
["metadata","labels","app"]
["metadata","name"]
["metadata","namespace"]
["spec","containers",0,"image"]
["spec","containers",0,"name"]
["spec","containers",0,"ports",0,"containerPort"]
["status","conditions",0,"lastTransitionTime"]
["status","conditions",0,"status"]
["status","phase"]
["status","podIP"]
```

#### Finding Specific Paths
```bash
# Find paths related to containers
$ kubectl get pod nginx-pod -o json | jq -c paths | grep "containers"
["spec","containers",0,"image"]
["spec","containers",0,"name"]
["spec","containers",0,"ports",0,"containerPort"]
["spec","containers",0,"resources","limits","cpu"]

# Find paths related to status
$ kubectl get pod nginx-pod -o json | jq -c paths | grep "status"
["status","phase"]
["status","podIP"]
["status","conditions",0,"status"]
```

#### Converting to JSONPath
The paths from `jq` can be easily converted to kubectl's JSONPath format:
- jq path: `["spec","containers",0,"image"]`
- kubectl JSONPath: `{.spec.containers[0].image}`

### Pro Tips
1. Use `grep` to filter for specific fields you're interested in
2. The numbers (like `0`) in paths indicate array indices
3. Save common path queries as aliases:
```bash
alias k8s-paths='kubectl get pod -o json | jq -c paths | grep'
# Usage: k8s-paths "cpu"
```

#### 2. Discovering Available Fields

Before writing queries, you can explore available fields:

```bash
# Find all available paths for a pod
$ kubectl get pod nginx-pod -o json | jq -c paths | grep "containers"
["spec","containers",0,"image"]
["spec","containers",0,"name"]
["spec","containers",0,"ports",0,"containerPort"]
["spec","containers",0,"resources","limits","cpu"]
["spec","containers",0,"resources","limits","memory"]
```

#### 3. Basic JSONPath Queries

##### Example 1: Get Pod Images
```bash
# List the image used by each pod
$ kubectl get pod -o jsonpath='{.items[*].spec.containers[0].image}'
nginx:1.19 redis:6.0 postgres:13
```

##### Example 2: Get Pod Names and Status
```bash
# Get pod names with their status
$ kubectl get pods -o jsonpath='{range .items[*]}{.metadata.name}{"t"}{.status.phase}{"n"}{end}'
web-pod-1    Running
cache-pod    Running
db-pod       Pending
```

#### 4. Custom Columns

##### Example 1: Basic Pod Information
```bash
$ kubectl get pods -o custom-columns=
NAME:.metadata.name,
STATUS:.status.phase,
IP:.status.podIP

NAME        STATUS    IP
web-pod-1   Running   10.244.0.23
cache-pod   Running   10.244.0.24
db-pod      Pending   <none>
```

##### Example 2: Container Resource Requests
```bash
$ kubectl get pods -o custom-columns=
POD:.metadata.name,
CPU:.spec.containers[0].resources.requests.cpu,
MEMORY:.spec.containers[0].resources.requests.memory

POD        CPU    MEMORY
web-pod-1  200m   256Mi
cache-pod  500m   1Gi
db-pod     1      2Gi
```

#### 5. Advanced Filtering

##### Example 1: Pods with Specific Labels
```bash
# Find all pods with app=web label
$ kubectl get pods -o jsonpath='{.items[?(@.metadata.labels.app=="web")].metadata.name}'
web-pod-1 web-pod-2 web-pod-3
```

##### Example 2: Containers Using Specific Images
```bash
# List pods running nginx
$ kubectl get pods -o custom-columns=
POD:.metadata.name,
IMAGE:.spec.containers[0].image | grep nginx

POD        IMAGE
web-pod-1  nginx:1.19
web-pod-2  nginx:1.19
```

#### 6. Real-World Examples

##### Example 1: Resource Usage Overview
```bash
$ kubectl get pods -o custom-columns=
NAME:.metadata.name,
CPU_REQ:.spec.containers[0].resources.requests.cpu,
CPU_LIM:.spec.containers[0].resources.limits.cpu,
MEM_REQ:.spec.containers[0].resources.requests.memory,
MEM_LIM:.spec.containers[0].resources.limits.memory

NAME        CPU_REQ  CPU_LIM  MEM_REQ  MEM_LIM
web-pod-1   200m     500m     256Mi    512Mi
cache-pod   500m     1        1Gi      2Gi
db-pod      1        2        2Gi      4Gi
```

##### Example 2: Network Configuration
```bash
$ kubectl get pods -o custom-columns=
NAME:.metadata.name,
IP:.status.podIP,
NODE:.spec.nodeName,
PORTS:.spec.containers[*].ports[*].containerPort

NAME        IP            NODE        PORTS
web-pod-1   10.244.0.23  worker-1    [80,443]
cache-pod   10.244.0.24  worker-2    [6379]
db-pod      <none>       worker-1    [5432]
```

#### 7. Practical Tips

##### Tip 1: Save Common Queries as Aliases
Add to your `~/.bashrc` or `~/.zshrc`:
```bash
# Alias for pod resource usage
alias k8s-resources='kubectl get pods -o custom-columns=
NAME:.metadata.name,
CPU:.spec.containers[0].resources.requests.cpu,
MEM:.spec.containers[0].resources.requests.memory'

# Usage
$ k8s-resources
NAME        CPU    MEM
web-pod-1   200m   256Mi
cache-pod   500m   1Gi
```

##### Tip 2: Combining with grep
```bash
# Find pods with high CPU requests
$ kubectl get pods -o custom-columns=NAME:.metadata.name,CPU:.spec.containers[0].resources.requests.cpu | grep "1"
db-pod      1
```

#### Common Patterns for Reference

1. Getting container information:
   ```bash
   .spec.containers[0].image           # First container's image
   .spec.containers[*].image           # All container images
   .spec.containers[?(@.name=="web")]  # Container named "web"
   ```

2. Status information:
   ```bash
   .status.phase                       # Pod phase
   .status.conditions[*].type          # All condition types
   .status.containerStatuses[0].ready  # First container ready status
   ```

3. Metadata and labels:
   ```bash
   .metadata.labels.app               # Value of label "app"
   .metadata.annotations             # All annotations
   .metadata.ownerReferences[0].kind # Owner kind (e.g., ReplicaSet)
   ```


## 5. Learn `awk` for Text Processing

`awk` is a powerful tool for extracting and formatting text, making it highly useful when working with Kubernetes, Docker, or CI/CD pipelines.

---

### Common Examples

#### Extract Image and Tag
Use `awk` to combine the image repository and tag for a cleaner output:

```bash
crictl images

Output:

IMAGE                                     TAG                 IMAGE ID            SIZE
docker.io/bitnami/nginx                   latest              d42eb6c65d81d       67.1MB
docker.io/kodekloud/webapp-color          latest              32a1ce4c22f21       31.8MB
docker.io/library/busybox                 <none>              27a71e19c9562       2.17MB
docker.io/library/busybox                 latest              517b897a6a831       2.17MB
docker.io/library/nginx                   1.13                ae513a47849c8       44.6MB
docker.io/library/nginx                   1.14                295c7be079025       44.7MB
docker.io/library/nginx                   1.16                dfcfd8e9a5d38       51MB
docker.io/library/nginx                   1.17                9beeba249f3ee       51MB
docker.io/library/nginx                   alpine              a5967740120f9       22.8MB
docker.io/library/nginx                   latest              3b25b682ea82b       73MB
docker.io/library/ubuntu                  latest              59ab366372d56       29.8MB

```bash
crictl images | awk '{print $1 ":" $2}'

Output:

IMAGE:TAG
docker.io/bitnami/nginx:latest
docker.io/kodekloud/webapp-color:latest
docker.io/library/busybox:<none>
docker.io/library/busybox:latest
docker.io/library/nginx:1.13
docker.io/library/nginx:1.14
docker.io/library/nginx:1.16
docker.io/library/nginx:1.17
docker.io/library/nginx:alpine
docker.io/library/nginx:latest


### Explanation:
- **`$1`**: Refers to the first column (image repository).
- **`$2`**: Refers to the second column (image tag).
- Combines both with `:` to output `repository:tag`.

Even further, you can add tail -n +2 to remove the IMAGE:TAG header

```bash
crictl images | tail -n +2 | awk '{print $1 ":" $2}'

Output:

docker.io/bitnami/nginx:latest
docker.io/kodekloud/webapp-color:latest
docker.io/library/busybox:<none>
docker.io/library/busybox:latest
...

---

### Filter and Format Output

Remove entries with `<none>` tags from the output:
```bash
crictl images | awk '$2 != "<none>" {print $1 ":" $2}'
```

### Scanning Filtered Images for CRITICAL Vulnerabilities Using `trivy`

This command filters images with names containing `nginx`, scans them for CRITICAL vulnerabilities using `trivy`, and prints only the "Total" line from the scan output.

#### Command:
```bash
for i in $(crictl images | awk '/nginx/ {print $1 ":" $2}'); do
  echo "Scanning $i for CRITICAL vulnerabilities...";
  trivy image $i --severity CRITICAL --quiet | grep Total;
done
```

* * * * *

### Explanation:

1.  Filter Images by Name:

    -   TheÂ `awk '/nginx/ {print $1 ":" $2}'`Â portion filters the images whose name contains the wordÂ `nginx`Â in the output ofÂ `crictl images`.
    -   It combines the first column (image repository) and the second column (image tag) intoÂ `repository:tag`Â format.
2.  Loop Through Filtered Images:

    -   TheÂ `for i in $(...)`Â loop iterates over each filtered image name and assigns it to the variableÂ `$i`.
3.  Scan Each Image:

    -   TheÂ `trivy image $i --severity CRITICAL --quiet`Â command runs a vulnerability scan for the current image:
        -   `--severity CRITICAL`: Limits the scan to CRITICAL vulnerabilities.
        -   `--quiet`: Suppresses non-essential output, such as logs and informational messages.
4.  Filter Scan Results:

    -   TheÂ `grep Total`Â command filters the output to include only the line containing the wordÂ `Total`, which summarizes vulnerability counts.

* * * * *

### Example Output:

For images likeÂ `nginx:latest`Â andÂ `nginx:alpine`, the command might produce output like this:

```bash
`Scanning docker.io/nginx:latest for CRITICAL vulnerabilities...
Total: 3 (CRITICAL: 1, HIGH: 2)

Scanning docker.io/nginx:alpine for CRITICAL vulnerabilities...
Total: 0 (CRITICAL: 0, HIGH: 0)`
```
* * * * *

### Key Notes:

-   Filtering by Image Name:

    -   TheÂ `/nginx/`Â filter inÂ `awk`Â ensures that only images with "nginx" in their name are included in the loop.
    -   You can replaceÂ `nginx`Â with any other keyword to filter specific images.
-   Focused Output:

    -   By usingÂ `--quiet`Â andÂ `grep Total`, the command ensures that only relevant results are displayed.
-   Custom Filters:

    -   Modify theÂ `awk`Â filter to match different image patterns or exclude specific tags (e.g.,Â `<none>`).

This approach combines flexibility and simplicity, making it efficient for scanning targeted images in your environment.


## 6. Network Diagnostics with `netcat`

### Testing Connectivity
```bash
# Test service in same namespace
kubectl exec -it my-pod -- sh
nc -zv service-name port

# Test cross-namespace service
nc -zv service-name.namespace.svc.cluster.local port

# Test Pod-to-Pod
kubectl exec -it source-pod -- sh
nc -zv target-pod-name port
```

## 7. Navigate Kubernetes Documentation

### Quick Tips
- Use `Ctrl + F` to find resource definitions with `kind: {resource}`
- Copy and modify sample manifests
- Bookmark frequently used pages

### Example: Creating a ServiceAccount
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-serviceaccount
```

## **8. Use `kubectl explain` for Quick Reference**

The `kubectl explain` command is an excellent tool for understanding Kubernetes resource structures and their fields. It provides detailed explanations of resource specifications and valid configurations.

---

### **Basic Usage**

1. **View Pod Spec Details**:
   ```bash
   kubectl explain pod.spec
   ```
   - **Explanation**:
     - Displays a high-level overview of the fields under `pod.spec`.

2. **Deep Dive into Container Configuration**:
   ```bash
   kubectl explain pod.spec.containers
   ```
   - **Explanation**:
     - Shows detailed information about the `containers` field, including subfields like `image`, `ports`, `env`, and more.

---

### **Recursive Option (`-r`)**

To explore nested fields and their subfields all at once, use the `-r` flag:

1. **View All Fields Under `pod.spec`**:
   ```bash
   kubectl explain pod.spec -r
   ```
   - **Explanation**:
     - Outputs all fields and subfields recursively, providing a complete breakdown of the pod specification.

2. **Inspect Container Subfields Recursively**:
   ```bash
   kubectl explain pod.spec.containers -r
   ```
   - **Explanation**:
     - Displays detailed information for all container fields, including environment variables, resource limits, probes, and more.

---

### **Why Use `-r`?**
- Saves time by showing the full structure of a resource.
- Useful for understanding deeply nested configurations like `volumes`, `env`, or `livenessProbe`.

---

### **Examples of Output**

**Without `-r`**:
```plaintext
KIND:     Pod
VERSION:  v1

FIELD:    containers <[]Object>

DESCRIPTION:
     List of containers belonging to the pod.
```

**With `-r`**:
```plaintext
KIND:     Pod
VERSION:  v1

FIELD:    containers <[]Object>

DESCRIPTION:
     List of containers belonging to the pod.

FIELDS:
   args     <[]string>
   command  <[]string>
   env      <[]Object>
   image    <string>
   name     <string>
   ports    <[]Object>
   resources <Object>
   ...
```

---

### **Tips for Using `kubectl explain`**
1. **Explore Any Resource**:
   Replace `pod` with any resource type (e.g., `deployment`, `service`, `pvc`):
   ```bash
   kubectl explain deployment.spec
   ```

2. **Quickly Verify Valid Fields**:
   Use it to confirm field names, especially when writing YAML manifests manually.

3. **Pair with `-r` for Learning**:
   The recursive option is particularly helpful when you're unfamiliar with a resource's full structure.

By using `kubectl explain` with the `-r` flag, you can dive deeper into Kubernetes resources and gain a better understanding of how to configure them effectively.


## 9. Validate with `--dry-run`
```bash
kubectl run infinite-logger 
  --image=busybox 
  --dry-run=client -o yaml 
  -- /bin/sh -c 'while true; do echo "Current time: $(date)" >> /data/logs/output.log; sleep 5; done' > infinite-logger-pod.yaml
```

Then you'll need to add the volume configuration separately by editing the YAML file using vim. The final YAML should look like:
```bash
apiVersion: v1
kind: Pod
metadata:
  name: infinite-logger
spec:
  containers:
    - name: infinite-logger
      image: busybox
      command: ["/bin/sh", "-c"]
      args:
        - while true; do echo "Current time: $(date)" >> /data/logs/output.log; sleep 5; done
      volumeMounts:
        - name: my-vol
          mountPath: /data
  volumes:
    - name: my-vol
      emptyDir: {}
```

# Validate the YAML
```bash
kubectl apply -f infinite-logger-pod.yaml --dry-run=client
```

# Generate deployment with loop
```bash
kubectl create deployment loop-deployment 
  --image=busybox 
  --replicas=2 
  --dry-run=client -o yaml 
  -- /bin/sh -c 'while true; do echo "Pod $HOSTNAME running"; sleep 10; done' > loop-deployment.yaml
```

## **10. Securing Workloads with Tools like AppArmor, gVisor, and Seccomp**

Securing workloads involves applying additional layers of protection to containers and their interactions with the host system.

---

### **AppArmor**

AppArmor is a Linux security module that restricts a program's capabilities based on a set of predefined profiles.

---

#### **Using AppArmor in Kubernetes**

1. **Check Existing Profiles**:
   List all available AppArmor profiles:
   ```bash
    apparmor_status
   ```

2. **Create a Custom AppArmor Profile**:
   Write a custom AppArmor profile and save it as `k8s-apparmor-example-deny-write`:
   ```plaintext
   #include <tunables/global>

   profile k8s-apparmor-example-deny-write flags=(attach_disconnected) {
       # Deny write access
       deny /bin/** w,
       deny /usr/bin/** w,
       deny /usr/sbin/** w,
   }
   ```

3. **Load the Profile**:
   Use `apparmor_parser` to load the profile into the kernel:
   ```bash
    apparmor_parser -r k8s-apparmor-example-deny-write
   ```

4. **Apply the Profile to a Pod**:
   Use the `securityContext` field to apply the AppArmor profile in your Pod spec:
   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: hello-apparmor
   spec:
     securityContext:
       appArmorProfile:
         type: Localhost
         localhostProfile: k8s-apparmor-example-deny-write
     containers:
     - name: hello
       image: busybox:1.28
       command: [ "sh", "-c", "echo 'Hello AppArmor!' && sleep 1h" ]
   ```

5. **Validate Profile Enforcement**:
   Confirm the profile is applied and enforced:
   ```bash
   kubectl exec hello-apparmor -- sh -c 'echo test > /usr/bin/testfile'
   ```
   The above command should fail due to the write restriction enforced by the AppArmor profile.

---

By correctly defining and applying AppArmor profiles using `securityContext`, you can enforce fine-grained security policies on your Kubernetes workloads, enhancing the protection against unauthorized actions.


---

### **Using gVisor in Kubernetes**

1. **Enable gVisor in Your Environment**:
   - Install the gVisor runtime (`runsc`) on each Kubernetes node.
   - Follow [gVisor installation documentation](https://gvisor.dev/docs/user_guide/install/) for your system.

2. **Configure RuntimeClass**:
   Create a `RuntimeClass` for gVisor:
   ```yaml
   apiVersion: node.k8s.io/v1
   kind: RuntimeClass
   metadata:
     name: gvisor
   handler: runsc
   ```

3. **Deploy a Pod Using gVisor**:
   To use gVisor, specify the `RuntimeClassName` in your Pod spec:
   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: nginx-gvisor
   spec:
     runtimeClassName: gvisor
     containers:
     - name: nginx
       image: nginx:latest
       ports:
       - containerPort: 80
   ```

4. **Verify gVisor is Applied**:
   - Check the Pod's runtime using:
     ```bash
     kubectl describe pod nginx-gvisor | grep -i "runtime"
     ```
   - Confirm that `runsc` is listed as the runtime.

5. **Simulate Workload Isolation**:
   gVisor restricts system calls. Test the container's isolation by attempting to access a restricted kernel feature:
   ```bash
   kubectl exec nginx-gvisor -- dmesg
   ```
   This command should fail due to gVisor's sandboxing.

---

### **Seccomp**

Seccomp limits system calls available to containerized applications, reducing the attack surface.

1. **Default Kubernetes Profiles**:
   Kubernetes provides built-in profiles:
   - `RuntimeDefault`: A default, secure profile.
   - `Unconfined`: No restrictions.

2. **Apply a Seccomp Profile**:
   Use the `securityContext` field in your Pod spec:
   ```yaml
   securityContext:
     seccompProfile:
       type: RuntimeDefault
   ```

3. **Custom Seccomp Profiles**:
   Mount a custom profile and reference it:
   ```yaml
   securityContext:
     seccompProfile:
       type: Localhost
       localhostProfile: profiles/my-custom-seccomp.json
   ```

4. **Validate Seccomp Enforcement**:
   ```bash
   kubectl exec <pod-name> -- grep Seccomp /proc/self/status
   ```

---

## **11. Using Falco for Runtime Security**

Falco is an open-source runtime security tool that monitors system calls to detect and alert on unexpected behavior, providing real-time protection for Kubernetes workloads.

---

### **Quick and Easy Tips for Using Falco**

#### **1. Check Falco Logs**
Falco logs events to the system log by default. To confirm the logging location:
```bash
cat /etc/falco/falco.yaml | grep -i log
```

Common log destinations:
- `/var/log/syslog` (Debian-based systems)
- `/var/log/messages` (RHEL-based systems)

You can verify logs with:
```bash
tail -f /var/log/syslog | grep falco
```

---

#### **2. Review and Customize Rules**
Falco comes with predefined rules for common threats (e.g., privilege escalation, sensitive file access). To customize a rule:

1. **Locate the Rule**:
   ```bash
   grep "<rule-name>" /etc/falco/falco_rules.yaml
   ```

2. **Copy the Rule to a Custom Rules File**:
   ```bash
   grep -A 10 "<rule-name>" /etc/falco/falco_rules.yaml > /etc/falco/custom_rules.yaml
   ```

3. **Edit the Custom Rule**:
   Adjust conditions, output messages, or priorities in `custom_rules.yaml`:
   ```yaml
   - rule: Write Below /etc
     desc: Detects writes below /etc directory
     condition: write and fd.name startswith /etc
     output: "File below /etc opened for writing (user=%user.name file=%fd.name)"
     priority: WARNING
   ```

4. **Reload Falco**:
   ```bash
   systemctl restart falco
   ```

---

#### **3. Test Rules Locally**
Simulate scenarios to validate rules:
- Example: Write to a restricted directory.
  ```bash
  echo "test" > /etc/test_file
  ```
  Check Falco logs for a triggered alert:
  ```bash
  tail -f /var/log/syslog | grep falco
  ```

---

#### **4. Integrate Falco with Kubernetes**
1. **View Falco Events in Kubernetes**:
   Falco can send events as Kubernetes Audit Logs. To configure:
   - Enable Kubernetes Audit Logging.
   - Set up Falco to monitor the audit log file:
     ```yaml
     falco:
       auditLog:
         enabled: true
         path: /var/log/kubernetes/audit.log
     ```
   - Restart Falco to apply changes.

2. **Output Events to Kubernetes Resources**:
   Falco can create Kubernetes resources like ConfigMaps or CRDs for detected threats:
   ```yaml
   json_output: true
   json_output_format: ecs
   grpc:
     enabled: true
     listen_port: 5060
   ```

---

#### **5. Use Predefined Falco Rules**
For quick setups, leverage the official [Falco rules repository](https://github.com/falcosecurity/falco).

Example rule to monitor shell execution:
```yaml
- rule: Terminal Shell in Container
  desc: Detect interactive terminal shells running in containers
  condition: container and shell
  output: "Interactive shell spawned in a container (user=%user.name container=%container.id)"
  priority: WARNING
  tags: [container, shell]
```

---

#### **6. Troubleshoot Falco**
1. **Validate Configuration**:
   Ensure the `falco.yaml` configuration is valid:
   ```bash
   falco --validate /etc/falco/falco.yaml
   ```

2. **Check Pod Logs** (if deployed in Kubernetes):
   ```bash
   kubectl logs <falco-pod-name> -n falco
   ```

3. **Inspect Runtime Logs**:
   ```bash
   journalctl -fu falco
   ```

---

By following these tips, you can quickly and effectively configure Falco for runtime security, customize rules for your environment, and monitor system calls to detect potential threats in Kubernetes clusters.


## **12. Auditing Kubernetes Clusters**

Auditing records all interactions with the Kubernetes API server.

### **Enable Auditing**

1. **Create an Audit Policy**:
   Save this as `audit-policy.yaml`:
   ```yaml
   apiVersion: audit.k8s.io/v1
   kind: Policy
   rules:
   - level: Metadata
     resources:
     - group: ""
       resources: ["pods", "services"]
   ```

2. **Configure API Server**:
   Update `kube-apiserver.yaml`:
   ```yaml
   spec:
     containers:
     - name: kube-apiserver
       volumeMounts:
       - mountPath: /etc/kubernetes/audit-policy.yaml
         name: audit-policy
         readOnly: true
       - mountPath: /var/log/kubernetes/audit.log
         name: audit-log
     volumes:
     - name: audit-policy
       hostPath:
         path: /etc/kubernetes/audit-policy.yaml
         type: File
     - name: audit-log
       hostPath:
         path: /var/log/kubernetes/audit.log
         type: FileOrCreate
   ```

---

## **13. Leveraging kube-bench for CIS Compliance**

kube-bench assesses your cluster against the Kubernetes CIS benchmark.

### **Does kube-bench Need to Be Installed Per Node?**
Yes, kube-bench typically needs to be run on each node individually because it checks configuration files and system settings that are specific to each node, such as the control plane components on master nodes or kubelet configurations on worker nodes.

1. **Install kube-bench**:
   ```bash
   curl -L https://github.com/aquasecurity/kube-bench/releases/latest/download/kube-bench-$(uname -s)-$(uname -m) -o kube-bench
   chmod +x kube-bench
    mv kube-bench /usr/local/bin
   ```

2. **Run kube-bench**:
   For master nodes:
   ```bash
   kube-bench --config-dir /etc/kube-bench/cfg --config /etc/kube-bench/cfg/config.yaml master
   ```

   For worker nodes:
   ```bash
   kube-bench --config-dir /etc/kube-bench/cfg --config /etc/kube-bench/cfg/config.yaml node
   ```

---

## **14. Kubernetes Troubleshooting Guide**

### Pod and Deployment Troubleshooting

### Start With Pod Status and Logs
```bash
# Check pod status and logs
kubectl describe pod <pod-name> -n <namespace>
kubectl logs <pod-name> -n <namespace>
kubectl logs <pod-name> -n <namespace> --previous  # If pod crashed

# Check recent events
kubectl get events -n <namespace> | grep <pod-name>
```

### Direct Pod Logs Access (when kubectl fails)
```bash
# List ALL pod log directories with timestamps
ls -lrt /var/log/pods/<namespace>_<pod-name>*   # newest last

# View latest log
cat /var/log/pods/<namespace>_<pod-name>    # [TAB]

# Follow latest log
tail -f /var/log/pods/<namespace>_<pod-name>    # [TAB]
```

### Container Runtime Investigation
```bash
# List containers
sudo crictl ps | grep <pod-name>
sudo crictl ps -a              # Include stopped containers

# Get container logs
sudo crictl logs <container_id>
```

## API Server Troubleshooting

### Start Here - Kubelet Perspective
```bash
# Check API server issues from kubelet
journalctl -u kubelet | grep -i kube-api | grep -i error

# Follow in real-time
journalctl -fu kubelet | grep -i kube-api | grep -i error
```

### Alternative Checks
```bash
# Check syslog for API server errors
cat /var/log/syslog | grep -i kube-api | grep -i error

# Check API server pod status
kubectl describe pod kube-apiserver-$(hostname) -n kube-system
```

### Direct Log Access
```bash
# List ALL API server log directories with timestamps
ls -lrt /var/log/pods/kube-system_kube-apiserver-*    # -rt sorts by time, newest last

# Or for clearer timestamp view
ls -lrth /var/log/pods/kube-system_kube-apiserver-*   # -h for human-readable sizes

# Use tab completion to select latest log
cat /var/log/pods/kube-system_kube-apiserver    # [TAB]

# Or follow the latest
tail -f /var/log/pods/kube-system_kube-apiserver    # [TAB]
```

ðŸ’¡ **Pro Tips**: 
- For pod issues: Start with kubectl describe and logs
- Use ls -lrt to sort by time (newest at bottom)
- If API server is restarting, you'll see new directories appear
- Use crictl when kubectl isn't responding
- Always check previous logs for crashed pods
- Static pods (like API server) are in /etc/kubernetes/manifests/

## **15. Pod-to-Pod Encryption with Cilium**

Cilium supports pod-to-pod encryption using IPsec or WireGuard.

### **Enable IPsec**:
Follow the [Cilium IPsec guide](https://docs.cilium.io/en/stable/security/network/encryption-ipsec/).

### **Enable WireGuard**:
Refer to the [Cilium WireGuard guide](https://docs.cilium.io/en/stable/security/network/encryption-wireguard/).

---

##  **16. Upgrading Kubernetes Clusters**

This guide covers upgrading from Kubernetes 1.30 to 1.31 as an example. Adjust version numbers according to your needs.

For comprehensive documentation, refer to the official Kubernetes upgrade guide:
https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/

## 1. Update Package Repositories

### For Ubuntu/Debian Systems:

```bash
# Add the repository configuration
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /" | \
  sudo tee /etc/apt/sources.list.d/kubernetes.list

# Add the key
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | \
  sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Update package index
sudo apt-get update
```

### For CentOS/RHEL Systems:

```bash
# Add new repository
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF
```

## 2. Control Plane Node Upgrade

### Preparation Steps

1. Verify current versions:
```bash
kubectl version --short
kubeadm version
kubelet --version
```

2. Check cluster health:
```bash
kubectl get nodes
kubectl get pods -A
```

3. Disable swap:
```bash
sudo swapoff -a
```

### Upgrade Control Plane Node

1. Cordon the control plane node:
```bash
# Replace master-node with your node name
kubectl cordon master-node
```

2. Update kubeadm:
```bash
# Example upgrading to 1.31.1-00
sudo apt-get update
sudo apt-get install -y kubeadm=1.31.1-00
kubeadm version
```

3. Plan and verify the upgrade:
```bash
sudo kubeadm upgrade plan
```

4. Apply the upgrade:
```bash
# Example upgrading to 1.31.1
sudo kubeadm upgrade apply v1.31.1
```

5. Upgrade kubelet and kubectl:
```bash
# For Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y kubelet=1.31.1-00 kubectl=1.31.1-00
sudo systemctl daemon-reload
sudo systemctl restart kubelet
```

6. Uncordon the control plane node:
```bash
kubectl uncordon master-node
```

7. Verify the upgrade:
```bash
kubectl get nodes
kubelet --version
```

## 3. Worker Nodes Upgrade

Repeat these steps for each worker node, one at a time.

### Drain Worker Node

1. Drain the node (from control plane):
```bash
# Replace worker-1 with your node name
kubectl drain worker-1 --ignore-daemonsets --delete-emptydir-data
```

### Upgrade Worker Node

1. On the worker node, upgrade kubeadm:
```bash
sudo apt-get update
sudo apt-get install -y kubeadm=1.31.1-00
```

2. Upgrade the node configuration:
```bash
sudo kubeadm upgrade node
```

3. Upgrade kubelet and kubectl:
```bash
sudo apt-get update
sudo apt-get install -y kubelet=1.31.1-00 kubectl=1.31.1-00
sudo systemctl daemon-reload
sudo systemctl restart kubelet
```

### Uncordon Worker Node

1. Make the node schedulable again (from control plane):
```bash
kubectl uncordon worker-1
```

## 4. Verify Cluster Status

```bash
# Check node versions
kubectl get nodes

# Verify all pods are running
kubectl get pods -A

# Check component status
kubectl get componentstatuses
```

## Common Issues and Solutions

1. **Pod Eviction Timeout**
   - If pods take too long to evict during drain:
   ```bash
   kubectl drain node-name --force --ignore-daemonsets --delete-emptydir-data --grace-period=30
   ```

2. **kubelet Service Fails**
   - Check logs:
   ```bash
   journalctl -xeu kubelet
   ```
   - Common fix for certificate issues:
   ```bash
   sudo kubeadm init phase kubelet-start
   ```

3. **API Server Unavailable**
   - Verify API server pod:
   ```bash
   kubectl get pods -n kube-system | grep api-server
   kubectl describe pod kube-apiserver-master -n kube-system
   ```

## Important Notes

- ðŸš¨ Always backup etcd before upgrading
- âš ï¸ Only upgrade one minor version at a time (e.g., 1.27.x â†’ 1.28.x)
- ðŸ“ Keep track of the exact versions you're upgrading to
- ðŸ”„ Plan for rollback in case of failure
- ðŸ• Schedule upgrade during maintenance window
- ðŸ“Š Monitor cluster health throughout the process

## **17. Backing Up and Restoring etcd**

etcd is the key-value store for Kubernetes. Itâ€™s essential to back it up regularly and know how to restore it in case of an issue.

### **1. Backup etcd**

#### **Step 1: Backup the Data**
Use `etcdctl` to take a snapshot:
   ```bash
   ETCDCTL_API=3 etcdctl snapshot save backup.db 
     --endpoints=https://127.0.0.1:2379 
     --cacert=/etc/kubernetes/pki/etcd/ca.crt 
     --cert=/etc/kubernetes/pki/etcd/server.crt 
     --key=/etc/kubernetes/pki/etcd/server.key
   ```

#### **Step 2: Verify the Snapshot**
Confirm the snapshot was saved:
   ```bash
   ETCDCTL_API=3 etcdctl snapshot status backup.db
   ```

---

### **2. Restore etcd**

#### **Step 1: Stop etcd**
Stop the etcd process before restoring:
   ```bash
   sudo systemctl stop etcd
   ```

#### **Step 2: Restore the Snapshot**
Use the following command to restore the backup:
   ```bash
   ETCDCTL_API=3 etcdctl snapshot restore backup.db 
     --data-dir=/var/lib/etcd-from-backup
   ```

#### **Step 3: Update etcd Configuration**
Edit the etcd configuration file (`/etc/kubernetes/manifests/etcd.yaml`) to point to the restored data directory:
   ```yaml
   spec:
     containers:
     - command:
       - --data-dir=/var/lib/etcd-from-backup
   ```

#### **Step 4: Restart etcd**
Start the etcd process:
   ```bash
   sudo systemctl start etcd
   ```

#### **Step 5: Verify etcd**
Check the cluster health:
   ```bash
   ETCDCTL_API=3 etcdctl endpoint health 
     --endpoints=https://127.0.0.1:2379 
     --cacert=/etc/kubernetes/pki/etcd/ca.crt 
     --cert=/etc/kubernetes/pki/etcd/server.crt 
     --key=/etc/kubernetes/pki/etcd/server.key
   ```

---

By following these instructions, you can perform a smooth Kubernetes upgrade and maintain the integrity of your etcd datastore.


### Time Management

## 18. File Organization Best Practices

- Use descriptive names: `question1-deployment.yaml`
- Keep backups: `cp file.yaml file-backup.yaml`
- Organize by resource type or question number

## 19. Debug YAML Efficiently

1. Validate syntax with `--dry-run`
2. Use vim to jump to error lines
3. Reapply after fixes

## 20. Time-Saving Aliases

```bash
alias k=kubectl
alias kgp='kubectl get pods'
alias kaf='kubectl apply -f'
```

## 21. Exam Strategy

### Time Management
- Start with easier questions
- Mark difficult questions for review
- Leave time for double-checking work

### Environment Setup
- Adjust terminal font size
- Set comfortable color scheme
- Test aliases before starting

## Practice Tips

- Set up a local cluster using `minikube` or `kind`
- Practice real-world scenarios
- Time yourself on practice questions
- Review and learn from mistakes

> ðŸŽ¯ **Remember**: Regular practice with these tools and techniques is key to exam success!

## 22. Terminal Navigation and Productivity Tips

These keyboard shortcuts and commands will significantly speed up your terminal work during the exam.

## Command History and Execution

### Previous Command Execution
- `!!` - Repeat the last command
  ```bash
  $ kubectl get pods           # Original command
  $ !!                        # Runs: kubectl get pods
  $ sudo !!                   # Runs: sudo kubectl get pods
  ```

### Command History Search
- `Ctrl + R` - Reverse recursive search
  ```bash
  # Press Ctrl + R and start typing
  (reverse-i-search)`kube': kubectl get pods
  # Press Ctrl + R again to cycle through matches
  (reverse-i-search)`kube': kubectl describe pod nginx
  ```
  
  ðŸ’¡ **Pro Tips for Recursive Search**:
  - Type unique parts of the command for better matches
  - Use `Ctrl + G` to cancel the search
  - Use `Ctrl + J` to copy the command without executing
  - Press `â†’` (right arrow) to edit the command before executing
  - Multiple `Ctrl + R` presses cycle through command history
  
- `history` - Show command history
- `!n` - Execute command number n from history
  ```bash
  $ history
  1234  kubectl get pods
  1235  kubectl get svc
  $ !1234                     # Runs: kubectl get pods
  ```

> ðŸŽ¯ **Exam Tip**: `Ctrl + R` is much faster than scrolling through history. Practice finding commands by their unique parts rather than memorizing history numbers.

## Cursor Navigation

### Line Navigation
- `Ctrl + A` - Move cursor to beginning of line
- `Ctrl + E` - Move cursor to end of line
- `Alt + B` - Move cursor back one word
- `Alt + F` - Move cursor forward one word
- `Ctrl + XX` - Toggle between current cursor position and start of line

### Text Deletion
- `Ctrl + U` - Delete from cursor to start of line
- `Ctrl + K` - Delete from cursor to end of line
- `Ctrl + W` - Delete the word before the cursor
- `Alt + D` - Delete the word after the cursor
- `Ctrl + D` - Delete character under cursor (like Delete key)
- `Ctrl + H` - Delete character before cursor (like Backspace)

## Terminal Screen Control
- `Ctrl + L` - Clear screen (same as `clear` command)
- `Ctrl + S` - Freeze terminal output
- `Ctrl + Q` - Resume terminal output
- `Ctrl + Z` - Suspend current process (return to shell)
- `fg` - Resume suspended process

## Quick Directory Navigation
- `cd -` - Go to previous directory
- `pushd directory` - Change directory and save location
- `popd` - Return to last saved directory location

## Command Line Editing
- `Ctrl + T` - Swap current character with previous
- `Alt + T` - Swap current word with previous
- `Alt + U` - Capitalize from cursor to end of word
- `Alt + L` - Lowercase from cursor to end of word
- `Alt + C` - Capitalize letter under cursor and move to end of word

## Pro Tips
1. **Multiple Command Execution**
   ```bash
   # Use && to run commands sequentially if previous succeeds
   kubectl create namespace test && kubectl create -f pod.yaml -n test

   # Use ; to run commands sequentially regardless of success
   kubectl get pods ; kubectl get svc
   ```

2. **Command Substitution**
   ```bash
   # Use $() for command substitution
   kubectl delete pod $(kubectl get pod -l app=nginx -o jsonpath='{.items[0].metadata.name}')
   ```

3. **Quick Comment/Uncomment**
   - `Ctrl + A` then `#` - Comment out current line
   - Remove `#` to uncomment

4. **Working with Shell Variables**

   ### Temporary Variables (Session Only)
   ```bash
   # Store common parameters
   ns="--namespace=kubernetes-dashboard"
   # Use in commands
   kubectl get pods $ns
   ```

   ### Permanent Variables (Persists Across Sessions)
   ```bash
   # Method 1: Echo and source in one command (Recommended for exam)
   echo 'export do="--dry-run=client -o yaml"' >> ~/.bashrc && source ~/.bashrc
   
   # Method 2: Edit directly (if you need to make multiple changes)
   vim ~/.bashrc
   
   # Method 3: Individual steps
   # Add to ~/.bashrc or ~/.bash_profile
   echo 'export ns="--namespace=kubernetes-dashboard"' >> ~/.bashrc
   # Apply changes to current session
   source ~/.bashrc
   ```

   ðŸ’¡ **Environment Variable Tips**:
   - Use `export` to make variables available to child processes
   - Common files for permanent variables:
     - `~/.bashrc`: User's bash configuration (most common)
     - `~/.bash_profile`: Login shell configuration
     - `~/.profile`: Non-bash-specific configuration
   - Use `printenv` or `env` to list all environment variables
   - Use `echo $VARIABLE` to check a specific variable's value
   
   Example permanent kubectl aliases:
   ```bash
   # Add to ~/.bashrc
   export do="--dry-run=client -o yaml"    # Quick YAML generation
   export now="--grace-period=0 --force"   # Quick deletion
   
   # Usage
   kubectl run nginx --image=nginx $do > pod.yaml
   kubectl delete pod mypod $now
   ```

ðŸ’¡ **Exam Tips**:
- Practice these shortcuts before the exam
- Pay special attention to cursor navigation (Ctrl+A, Ctrl+E) and deletion (Ctrl+U, Ctrl+K)
- Master command history with `!!` and `sudo !!` for quick command repetition
- Remember `Ctrl + R` for searching command history - vital for long commands
